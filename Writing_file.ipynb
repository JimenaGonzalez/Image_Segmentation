{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = False\n",
    "cluster = False\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "plt.style.use('dark_background')\n",
    "import random\n",
    "from scipy.stats import skewnorm\n",
    "import copy\n",
    "from distutils.util import strtobool\n",
    "\n",
    "if(script): \n",
    "    from tqdm import tqdm\n",
    "else:\n",
    "    from tqdm.notebook import tqdm\n",
    "    import ipython_bell\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "\n",
    "import lenstronomy.Util.param_util as param\n",
    "import lenstronomy.Util.util as util\n",
    "from lenstronomy.SimulationAPI.sim_api import SimAPI\n",
    "from lenstronomy.LensModel.lens_model import LensModel\n",
    "from lenstronomy.LensModel.lens_model_extensions import LensModelExtensions\n",
    "from lenstronomy.LensModel.Solver.lens_equation_solver import LensEquationSolver\n",
    "\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DES_camera = {'read_noise': 7.,  # std of noise generated by read-out (in units of electrons)\n",
    "               'pixel_scale': 0.2637,  # scale (in arcseconds) of pixels\n",
    "               'ccd_gain': 4.#6.  # electrons/ADU (analog-to-digital unit). A gain of 8 means that the camera digitizes the CCD signal so that each ADU corresponds to 8 photoelectrons.\n",
    "              }\n",
    "\n",
    "DES_g_band_obs = {'exposure_time': 90.,  # exposure time per image (in seconds)\n",
    "                   'sky_brightness': 35.01,  # sky brightness (in magnitude per square arcseconds)\n",
    "                   'magnitude_zero_point': 30,  # magnitude in which 1 count per second per arcsecond square is registered (in ADU's)\n",
    "                   'num_exposures': 10.,  # number of exposures that are combined\n",
    "                   'seeing': 1.12,  # full width at half maximum of the PSF (if not specific psf_model is specified)\n",
    "                   'psf_type': 'GAUSSIAN',  # string, type of PSF ('GAUSSIAN' and 'PIXEL' supported)\n",
    "                   'kernel_point_source': None  # 2d numpy array, model of PSF centered with odd number of pixels per axis (optional when psf_type='PIXEL' is chosen)\n",
    "                  }\n",
    "\n",
    "DES_r_band_obs = {'exposure_time': 90.,  \n",
    "                   'sky_brightness': 34.7,  \n",
    "                   'magnitude_zero_point': 30,  \n",
    "                   'num_exposures': 10.,  \n",
    "                   'seeing': 1.12,  \n",
    "                   'psf_type': 'GAUSSIAN', \n",
    "                  }\n",
    "\n",
    "DES_i_band_obs = {'exposure_time': 90.,  \n",
    "                   'sky_brightness': 35.1,  \n",
    "                   'magnitude_zero_point': 30,  \n",
    "                   'num_exposures': 10.,  \n",
    "                   'seeing': 1.12,  \n",
    "                   'psf_type': 'GAUSSIAN', \n",
    "                  }\n",
    "\n",
    "numpix = 45 # 45\n",
    "\n",
    "kwargs_g_band = util.merge_dicts(DES_camera, DES_g_band_obs)\n",
    "kwargs_r_band = util.merge_dicts(DES_camera, DES_r_band_obs)\n",
    "kwargs_i_band = util.merge_dicts(DES_camera, DES_i_band_obs)\n",
    "\n",
    "kwargs_numerics = {'point_source_supersampling_factor': 10}\n",
    "\n",
    "cosmo = FlatLambdaCDM(H0=70, Om0=0.3, Ob0=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Seeds basic parameters for reproductibility of results\n",
    "    Arguments:\n",
    "        seed {int} -- Number of the seed\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pick a position very close to the caustic\n",
    "def pick_center1(ra_caustic_list, dec_caustic_list):\n",
    "    l = random.randint(0, len(ra_caustic_list)-1)\n",
    "    noise_ra, noise_dec = random.uniform(-0.8, 0.8), random.uniform(-0.8, 0.8)\n",
    "    return(ra_caustic_list[l] + noise_ra, dec_caustic_list[l] + noise_dec)\n",
    "\n",
    "#Distribution that includes more positions further away from the center\n",
    "def pick_center(ra_caustic_list, dec_caustic_list):\n",
    "    l = random.randint(0, len(ra_caustic_list)-1)\n",
    "    t = skewnorm.rvs(a=-5, size=10000, loc=0.8, scale=0.435) #a: skew, loc: center, scale:sigma\n",
    "    noise_ra, noise_dec = t[np.random.randint(0,10000)], t[np.random.randint(0,10000)]\n",
    "    s_ra = 1 if random.randint(0, 1) else -1\n",
    "    s_dec = 1 if random.randint(0, 1) else -1\n",
    "    noise_ra, noise_dec = s_ra*noise_ra, s_dec*noise_dec\n",
    "    return(ra_caustic_list[l] + noise_ra, dec_caustic_list[l] + noise_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes 3 plots per image: source simulation, lens cutout, complete simulation\n",
    "def make_graphs(name, sim_i, sim_r, sim_g, cutout_i, cutout_r, cutout_g):\n",
    "    loc = plticker.MultipleLocator(base=3.75)\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(figsize=(15, 4), ncols=3)\n",
    "\n",
    "    rgb = make_lupton_rgb(sim_i, sim_r, sim_g, Q=11., stretch=40.)\n",
    "    ax1.set_title('Source(s)')\n",
    "    ax1.xaxis.set_ticklabels([])\n",
    "    ax1.yaxis.set_ticklabels([])\n",
    "    original = ax1.imshow(rgb, aspect='equal')\n",
    "\n",
    "    rgb = make_lupton_rgb(cutout_i, cutout_r, cutout_g, Q=11., stretch=40.)\n",
    "    ax2.set_title('Lens')\n",
    "    ax2.xaxis.set_ticklabels([])\n",
    "    ax2.yaxis.set_ticklabels([])\n",
    "    cutout = ax2.imshow(rgb, aspect='equal')\n",
    "            \n",
    "    rgb = make_lupton_rgb(sim_i+cutout_i, sim_r+cutout_r, sim_g+cutout_g, Q=11., stretch=40.)\n",
    "    ax3.set_title('Complete Simulation')\n",
    "    ax3.xaxis.set_ticklabels([])\n",
    "    ax3.yaxis.set_ticklabels([])\n",
    "    projection = ax3.imshow(rgb, aspect='equal')\n",
    "   \n",
    "    sub_path = '/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/'\n",
    "    #plt.savefig(sub_path + 'Data/Sim_complete/Image' + name + '.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes fit file\n",
    "def write_fit_file(name, images, data):\n",
    "    my_types = {'Y6_COADD_OBJECT_ID': int, 'TILENAME': str, 'HPIX_16384': int, 'HPIX_4096': int,\n",
    "       'DNF_ZMEAN_SOF': float, 'RA': float, 'DEC': float, 'FLUX_RADIUS_G': float, 'FLUX_RADIUS_R': float,\n",
    "       'FLUX_RADIUS_I': float, 'FLUX_RADIUS_Z': float, 'KRON_RADIUS': float, 'GAP_FLUX_G': float,\n",
    "       'MOF_BDF_FLUX_G': float, 'MOF_PSF_FLUX_G': float, 'SOF_BDF_FLUX_G': float, 'SOF_PSF_FLUX_G': float,\n",
    "       'MAG_AUTO_G': float, 'MAG_APER_4_G': float, 'MAG_APER_8_G': float, 'SOF_BDF_G_1': float,\n",
    "       'Y3_COADD_OBJECT_ID': int, 'REFMAG': float, 'REFMAG_ERR': float, 'LUM': float, 'ZREDMAGIC': float,\n",
    "       'ZREDMAGIC_E': float, 'CHISQ': float, 'Z_LENS': float, 'MAG_G': float, 'MAG_R': float, 'MAG_I': float, 'MAG_Z': float,\n",
    "       'MAG_ERR_G': float, 'MAG_ERR_R': float, 'MAG_ERR_I': float, 'MAG_ERR_Z': float, 'ZG': float, 'ZR': float, 'ZI': float,\n",
    "       'ZZ': float, 'SOF_BDF_G_2': float, 'IMAFLAGS_ISO_G': int, 'IMAFLAGS_ISO_R': int,\n",
    "       'IMAFLAGS_ISO_I': int, 'IMAFLAGS_ISO_Z': int, 'EXT_COADD': int, 'FWHM_WMEAN_G': float,\n",
    "       'FWHM_WMEAN_R': float, 'FWHM_WMEAN_I': float, 'FWHM_WMEAN_Z': float, 'SKYBRITE_WMEAN_G': float,\n",
    "       'SKYBRITE_WMEAN_R': float, 'SKYBRITE_WMEAN_I': float, 'SKYBRITE_WMEAN_Z': float, 'Z1': float, 'LENSED_MAG': float,     \n",
    "       'mag_1': float, 'ISOLATION': float, 'EINSTEIN_RADIUS': float, 'MAGNIFICATION': float, 'POSITION1': float}\n",
    "    if(double):\n",
    "        tmp_types = {'Z2': float, 'mag_2': float, 'POSITION2': float, 'dif_color': float}\n",
    "        my_types.update(tmp_types)\n",
    "    data = data.astype(my_types)\n",
    "    \n",
    "    sim_images, source_images, lens_images = images[0], images[1], images[2]\n",
    "    \n",
    "    primary = fits.PrimaryHDU()\n",
    "    image1 = fits.ImageHDU(sim_images, name=\"IMAGE\")\n",
    "    image2 = fits.ImageHDU(source_images, name=\"IMAGE\")\n",
    "    image3 = fits.ImageHDU(lens_images, name=\"IMAGE\")\n",
    "    table_data = Table.from_pandas(data)\n",
    "    table = fits.BinTableHDU(data = table_data)\n",
    "    hdu_list = fits.HDUList([primary, image1, image2, image3, table])\n",
    "    hdu_list.writeto(file_path + name + '.fits', overwrite=True)   \n",
    "    hdu_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating distance of the furtherst image to the lens center\n",
    "def furtherst_distance(theta_ra, theta_dec):\n",
    "    distances_list = []\n",
    "    for i in range(len(theta_ra)):\n",
    "        distances_list.append(np.sqrt(theta_ra[i]**2 + theta_dec[i]**2))\n",
    "    return(max(distances_list))\n",
    "\n",
    "\n",
    "#Calculating ~total flux\n",
    "def calculate_flux(object, band):\n",
    "    flux = np.sum(object[band])\n",
    "    return(flux)\n",
    "\n",
    "#Calculating AB magnitude\n",
    "def calculate_magnitude(object, band):\n",
    "    f = calculate_flux(object, band)\n",
    "    m = -2.5*np.log10(f*10**(-12))\n",
    "    return(m)\n",
    "\n",
    "def calculate_magnification(delta_m):\n",
    "    M = 100**(delta_m/5)\n",
    "    return(M)\n",
    "\n",
    "def isolation(image_source, image_lens, cumulative=0.9):\n",
    "    \"\"\"Compute a statistic to measure degree of source image isolation.\n",
    "   \n",
    "    Use the simulated image of the lensed source to define an effective weight\n",
    "    map. Use the weight map to compute the weighted average flux within pixels \n",
    "    from the lensed source images and from the foreground lens. Return the \n",
    "    effective fraction of the total flux within this weighted aperture that is\n",
    "    attributed to the source.\n",
    "\n",
    "    isolation = <source_flux> / (<source_flux> + <lens_flux>)\n",
    " \n",
    "    A weighted aperture is obtained by converting the simulated source image \n",
    "    into a PDF, removing the set of faint pixels that contain (1 - cumulative)\n",
    "    of the total flux, and normalizing the weighted aperture such that integral \n",
    "    over all pixels in equal to one.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_source : `numpy.ndarray` [`float`]\n",
    "        Image of simulated lensed source; shape (n, n)\n",
    "    image_lens : `np.ndarray` [`float`]\n",
    "        Image of lens and other foreground objects; shape (n, n)\n",
    "    cumulative : `float`\n",
    "        Fraction of lens total flux to use when defining an aperture. \n",
    "        Default = 0.9.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    isolation : `float`\n",
    "        Mean flux fraction attributed to the source images within the weighted\n",
    "        apertue.\n",
    "    \"\"\"\n",
    "    \n",
    "    weight = image_source  / np.sum(image_source)\n",
    "    weight_sorted = np.sort(weight.flatten())\n",
    "    threshold = weight_sorted[np.cumsum(weight_sorted) > (1. - cumulative)][0]\n",
    "    aperture = weight > threshold\n",
    "\n",
    "    weight_aperture = weight * aperture / np.sum(weight * aperture)\n",
    "\n",
    "    mean_lens = np.sum(weight_aperture * image_lens) \n",
    "    mean_sources = np.sum(weight_aperture * image_source)\n",
    "    isolation = mean_sources / (mean_sources + mean_lens)\n",
    "    return isolation\n",
    "\n",
    "# From redshift get magnitude, sersic radius & ellipticity\n",
    "def distribution(z, data):\n",
    "    dz = 0.1 # Range of redshift for filtering\n",
    "    new_data = data[data['DNF_ZMEAN_SOF'] > z - dz] [data['DNF_ZMEAN_SOF'] < z + dz] \n",
    "    new_data = new_data[new_data['MAG_PSF_G'] < MMAX]\n",
    "    if(double):\n",
    "        new_data = new_data[new_data['MAG_PSF_G'] > MMIN]\n",
    "    random_object = new_data.sample()\n",
    "    mg, mr, mi = random_object['MAG_PSF_G'].values[0], random_object['MAG_PSF_R'].values[0], random_object['MAG_PSF_I'].values[0]\n",
    "    rg, rr, ri = random_object['FLUX_RADIUS_G'].values[0], random_object['FLUX_RADIUS_R'].values[0], random_object['FLUX_RADIUS_I'].values[0]\n",
    "    e1, e2 = random_object['SOF_CM_G_1'].values[0], random_object['SOF_CM_G_2'].values[0]\n",
    "    magnitude = {'mg': mg -2., 'mr': mr-2., 'mi': mi-2.}\n",
    "    radius = {'rg': rg*DES_camera['pixel_scale'], 'rr': rr*DES_camera['pixel_scale'], 'ri': ri*DES_camera['pixel_scale']}\n",
    "    ellipticity = {'e1': e1, 'e2': e2}\n",
    "    return(magnitude, radius, ellipticity)\n",
    "    #z = 1.7 Max\n",
    "\n",
    "def distribution_data(path):\n",
    "    data_dist = pd.read_csv(path)\n",
    "    data_dist = data_dist[data_dist['MAG_PSF_G'] < 30.] [data_dist['MAG_PSF_R'] < 30.] [data_dist['MAG_PSF_I'] < 30.]\n",
    "    data_dist = data_dist[data_dist['SOF_CM_G_1'] > -100.][data_dist['SOF_CM_G_2'] > -100.]\n",
    "    data_dist = data_dist[data_dist['DNF_ZMEAN_SOF'] > 0.01][data_dist['DNF_ZMEAN_SOF'] < 2.9]\n",
    "    data_dist = data_dist.sort_values('DNF_ZMEAN_SOF').reset_index()\n",
    "    return(data_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(model, coadd_id, redshifts, lens_image, lens, cuts, double, additional_info):\n",
    "   \n",
    "    kwargs_model_physical = {'lens_model_list': ['SIE'],  # list of lens models to be used\n",
    "                          'lens_redshift_list': [redshifts['lens']],  # list of redshift of the deflections\n",
    "                          # list of extended source models to be used\n",
    "                          'source_light_model_list': ['SERSIC_ELLIPSE'],  \n",
    "                          # list of redshfits of the sources in same order as source_light_model_list\n",
    "                          'source_redshift_list': [redshifts['source1']],  \n",
    "                          'cosmo': cosmo,  # astropy.cosmology instance\n",
    "                          # redshift of the default source (if not further specified by 'source_redshift_list')\n",
    "                          'z_source': redshifts['source1']} \n",
    "                           #and also serves as the redshift of lensed point sources}\n",
    "\n",
    "    if(double == True):\n",
    "        kwargs_model_physical['source_light_model_list'].append('SERSIC')\n",
    "        kwargs_model_physical['source_redshift_list'].append(redshifts['source2'])\n",
    "        kwargs_model_physical['z_source'] = redshifts['source2']\n",
    "        \n",
    "    sim_g = SimAPI(numpix=numpix, kwargs_single_band=kwargs_g_band, kwargs_model=kwargs_model_physical)\n",
    "    sim_r = SimAPI(numpix=numpix, kwargs_single_band=kwargs_r_band, kwargs_model=kwargs_model_physical)\n",
    "    sim_i = SimAPI(numpix=numpix, kwargs_single_band=kwargs_i_band, kwargs_model=kwargs_model_physical)\n",
    "    \n",
    "    imSim_g = sim_g.image_model_class(kwargs_numerics)\n",
    "    imSim_r = sim_r.image_model_class(kwargs_numerics)\n",
    "    imSim_i = sim_i.image_model_class(kwargs_numerics)\n",
    "\n",
    "    #lens mass model\n",
    "    kwargs_mass = [{'sigma_v': lens['sigma'], 'center_x': 0, 'center_y': 0, \n",
    "                    'e1': lens['e1'], 'e2': lens['e2']}]\n",
    "    kwargs_lens = sim_g.physical2lensing_conversion(kwargs_mass=kwargs_mass)\n",
    "    \n",
    "    #caustics and critical curves\n",
    "    ra_crit_list, dec_crit_list, ra_caustic_list, dec_caustic_list = model['model_ext'].critical_curve_caustics(kwargs_lens, \n",
    "                                                                compute_window=15, grid_scale=0.01, center_x=0, center_y=0)\n",
    "    if(len(ra_caustic_list)==0): return('No caustics')\n",
    "    ra_caustic_list, dec_caustic_list = ra_caustic_list[0], dec_caustic_list[0]\n",
    "    \n",
    "    #cut on the Einstein radius of the lens\n",
    "    if(kwargs_lens[0]['theta_E'] < cuts['E_min'] or kwargs_lens[0]['theta_E'] > cuts['E_max']):\n",
    "        return ('No cut E: {:.3f}'.format(kwargs_lens[0]['theta_E']))\n",
    "    \n",
    "    #cut comparing Einstein radius and size of the lens\n",
    "    E_rflux = kwargs_lens[0]['theta_E']/additional_info['FLUX_RADIUS_G']\n",
    "    if(E_rflux < cuts['theta_E_r_f_min'] or E_rflux > cuts['theta_E_r_f_max']):\n",
    "        return ('No cut E_r: {:.3f}'.format(E_rflux))\n",
    "    \n",
    "    #First source light distributions & colors of the other bands for each source\n",
    "    mag1, rad1, ellip1 = distribution(redshifts['source1'], data = data_dist)\n",
    "    n1 = random.uniform(0.3, 4.)\n",
    "    #Pick center of first source on the caustic\n",
    "    c1x, c1y = pick_center(ra_caustic_list, dec_caustic_list)\n",
    "    \n",
    "    theta_ra1, theta_dec1 = model['solver'].image_position_from_source(c1x, c1y, kwargs_lens)\n",
    "    if(len(theta_ra1)==0): return('No image positions')\n",
    "    #magni1 = model['lensModel'].magnification(theta_ra1, theta_dec1, kwargs_lens)\n",
    "    \n",
    "    distance1 = furtherst_distance(theta_ra1, theta_dec1)\n",
    "    if(distance1 < cuts['min_image'] or distance1 > cuts['max_image']):\n",
    "        return('No cut image: {:.3f}'.format(distance1))\n",
    "    \n",
    "    \n",
    "    #First source light:\n",
    "    kwargs_source_mag_g_1 = [{'magnitude': mag1['mg'], 'R_sersic': rad1['rg'], 'n_sersic': n1,\n",
    "                              'e1': ellip1['e1'], 'e2': ellip1['e2'], 'center_x': c1x, 'center_y': c1y}]\n",
    "    #Adding color distribution to the bands (first source):\n",
    "    kwargs_source_mag_r_1 = copy.deepcopy(kwargs_source_mag_g_1)\n",
    "    kwargs_source_mag_r_1[0]['magnitude'], kwargs_source_mag_r_1[0]['R_sersic'] = mag1['mr'], rad1['rr']\n",
    "    kwargs_source_mag_i_1 = copy.deepcopy(kwargs_source_mag_g_1)\n",
    "    kwargs_source_mag_i_1[0]['magnitude'], kwargs_source_mag_i_1[0]['R_sersic'] = mag1['mi'], rad1['ri']\n",
    "    #Same for second source\n",
    "    if(double == True):\n",
    "        mag2, rad2, ellip2 = distribution(redshifts['source2'], data = data_dist)\n",
    "        n2 = random.uniform(0.3, 4.)\n",
    "        c2x, c2y = pick_center(ra_caustic_list, dec_caustic_list)\n",
    "        theta_ra2, theta_dec2 = model['solver'].image_position_from_source(c2x, c2y, kwargs_lens)\n",
    "        if(len(theta_ra2)==0): return('No image positions')\n",
    "        distance2 = furtherst_distance(theta_ra2, theta_dec2)\n",
    "        if(distance2 < cuts['min_image'] or distance2 > cuts['max_image']):\n",
    "            return('No cut image: {:.3f}'.format(distance1))\n",
    "        #magni2 = model['lensModel'].magnification(theta_ra2, theta_dec2, kwargs_lens)\n",
    "        kwargs_source_mag_g_2 = [{'magnitude': mag2['mg'], 'R_sersic': rad2['rg'], 'n_sersic': n2, \n",
    "                              'center_x': c2x, 'center_y': c2y}]\n",
    "        kwargs_source_mag_r_2 = copy.deepcopy(kwargs_source_mag_g_2)\n",
    "        kwargs_source_mag_r_2[0]['magnitude'], kwargs_source_mag_r_2[0]['R_sersic'] = mag2['mr'], rad2['rr']\n",
    "        kwargs_source_mag_i_2 = copy.deepcopy(kwargs_source_mag_g_2)\n",
    "        kwargs_source_mag_i_2[0]['magnitude'], kwargs_source_mag_i_2[0]['R_sersic'] = mag2['mi'], rad2['ri']\n",
    "        #print(distance1, distance2)\n",
    "        if(distance2 < cuts['min_image'] or distance2 > cuts['max_image']):\n",
    "            return('No cut image: {:.3f}'.format(distance1))\n",
    "        if(abs(distance1 - distance2) < 1.): return('No distance between images')\n",
    "        dif_1 = abs(mag1['mg']-mag1['mi'] - (mag2['mg']-mag2['mi']))\n",
    "        dif_2 = abs(mag1['mg']-mag1['mr'] - (mag2['mg']-mag2['mr']))\n",
    "        color_dif = dif_1 + dif_2\n",
    "        if(color_dif < cuts['min_col']):\n",
    "            return('No cut color: {:.3f}'.format(color_dif))\n",
    "        \n",
    "    kwargs_source_mag_g = kwargs_source_mag_g_1 + kwargs_source_mag_g_2 if(double) else kwargs_source_mag_g_1 \n",
    "    kwargs_source_mag_r = kwargs_source_mag_r_1 + kwargs_source_mag_r_2 if(double) else kwargs_source_mag_r_1 \n",
    "    kwargs_source_mag_i = kwargs_source_mag_i_1 + kwargs_source_mag_i_2 if(double) else kwargs_source_mag_i_1 \n",
    "    \n",
    "    kwargs_lens_light_g, kwargs_source_g , point = sim_g.magnitude2amplitude(kwargs_lens_light_mag=None, \n",
    "                                                    kwargs_source_mag=kwargs_source_mag_g, kwargs_ps_mag=None)\n",
    "    kwargs_lens_light_r, kwargs_source_r , point = sim_r.magnitude2amplitude(kwargs_lens_light_mag=None, \n",
    "                                                    kwargs_source_mag=kwargs_source_mag_r, kwargs_ps_mag=None)\n",
    "    kwargs_lens_light_i, kwargs_source_i , point = sim_i.magnitude2amplitude(kwargs_lens_light_mag=None, \n",
    "                                                    kwargs_source_mag=kwargs_source_mag_i, kwargs_ps_mag=None)\n",
    "    \n",
    "    image_g = imSim_g.image(kwargs_lens, kwargs_source_g)\n",
    "    image_r = imSim_r.image(kwargs_lens, kwargs_source_r)\n",
    "    image_i = imSim_i.image(kwargs_lens, kwargs_source_i)\n",
    "    \n",
    "    image_g += sim_g.noise_for_model(model=image_g)\n",
    "    image_r += sim_r.noise_for_model(model=image_r)\n",
    "    image_i += sim_i.noise_for_model(model=image_i)\n",
    "    \n",
    "    image_g = image_g[::-1]\n",
    "    image_r = image_r[::-1]\n",
    "    image_i = image_i[::-1]\n",
    "    \n",
    "    if(np.isnan(np.sum(image_g))): \n",
    "        return('IS NAN!!!!!')\n",
    "    \n",
    "    object_sim = np.array([image_g, image_r, image_i])\n",
    "    m = calculate_magnitude(object_sim, 0) #band 0 = g band\n",
    "\n",
    "    if((m > cuts['mmax'] or m < cuts['mmin']) and double == False):\n",
    "        return ('No cut mag: {:.3f}'.format(m))\n",
    "    \n",
    "    lens_g, lens_r, lens_i = lens_image[0], lens_image[1], lens_image[2]\n",
    "    iso_g, iso_i, iso_r = isolation(image_g,lens_g), isolation(image_i, lens_i), isolation(image_r, lens_r)\n",
    "    iso_ave = np.mean([iso_g, iso_i, iso_r])\n",
    "    Mag = calculate_magnification(mag1['mg'] - m)\n",
    "    \n",
    "    if(iso_ave < cuts['iso_min'] or iso_ave > cuts['iso_max'] or np.isnan(iso_ave)): \n",
    "        return('No cut isolation: {:.3f}'.format(iso_ave))\n",
    "    \n",
    "    if(Mag < cuts['magni_min'] or Mag > cuts['magni_max'] or np.isnan(Mag)): \n",
    "        return('No cut magnification: {:.3f}'.format(Mag))\n",
    "    \n",
    "    parameters = {'Z1': redshifts['source1'], 'LENSED_MAG': m, 'mag_1': mag1['mg'], \n",
    "                  'ISOLATION': iso_ave, 'EINSTEIN_RADIUS': kwargs_lens[0]['theta_E'], 'MAGNIFICATION': Mag,\n",
    "                 'POSITION1': distance1}\n",
    "    if(double):\n",
    "        tmp_para = {'Z2': redshifts['source2'], 'mag_2': mag2['mg'], 'POSITION2': distance2, 'dif_color': color_dif}\n",
    "        parameters.update(tmp_para)\n",
    "        \n",
    "    tmp_series = pd.Series(parameters)\n",
    "    additional_info = pd.concat([additional_info, tmp_series])\n",
    "    df_test = pd.DataFrame(additional_info).transpose()\n",
    "    parameters = df_test\n",
    "      \n",
    "    krand, intrand = random.randint(0, 4), random.randint(0, 1)\n",
    "    \n",
    "    source_image = np.array([image_g, image_r, image_i])\n",
    "    lens_image = np.array([lens_g, lens_r, lens_i])\n",
    "    \n",
    "    source_image = np.rot90(source_image, k=krand, axes=(1, 2))\n",
    "    lens_image = np.rot90(lens_image, k=krand, axes=(1, 2))\n",
    "    \n",
    "    if(intrand == 1): \n",
    "        source_image = np.flip(source_image, 2)\n",
    "        lens_image = np.flip(lens_image, 2)\n",
    "        \n",
    "    images = [source_image + lens_image, source_image, lens_image]\n",
    "    #print(coadd_id)\n",
    "\n",
    "    #if(not script):\n",
    "    #    make_graphs('example_simulations', image_i, image_r, image_g, lens_i, lens_r, lens_g)\n",
    "        \n",
    "    return ('ok', images, parameters)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def simulations_from_data(lenses, complete_data, num, double):\n",
    "    num_sim = 0\n",
    "    sim_images, source_images, lens_images = np.zeros((1,3,numpix,numpix)), np.zeros((1,3,numpix,numpix)), np.zeros((1,3,numpix,numpix))\n",
    "    data_sim = pd.DataFrame()\n",
    "\n",
    "    lens_model_list = ['SIE']\n",
    "    lensModel = LensModel(lens_model_list=lens_model_list)\n",
    "    lensModelExt = LensModelExtensions(lensModel)\n",
    "    solver = LensEquationSolver(lensModel)\n",
    "    \n",
    "    model = {'lensModel': lensModel, 'model_ext': lensModelExt, 'solver': solver}\n",
    "    \n",
    "    with tqdm(total=num) as pbar:\n",
    "        while (num_sim < num):\n",
    "            l = random.randint(0, len(complete_data)-1)\n",
    "            row = complete_data.iloc[l]\n",
    "            lens_image = lenses[l]\n",
    "            \n",
    "            DES_g_band_obs['seeing'] = row['FWHM_WMEAN_G'] \n",
    "            DES_r_band_obs['seeing'] = row['FWHM_WMEAN_R']\n",
    "            DES_i_band_obs['seeing'] = row['FWHM_WMEAN_I']\n",
    "\n",
    "            coadd_id = int(row['Y6_COADD_OBJECT_ID'])\n",
    "            z_lens = row['Z_LENS']\n",
    "            z1_max = skewnorm.rvs(a=-5, size=10000, loc=1.2, scale=0.4)  #0.2, 1.2   0.8 for DSPL\n",
    "            if(double):\n",
    "                z1_max = skewnorm.rvs(a=-5, size=1000, loc=0.8, scale=0.5)\n",
    "            z1_max = z1_max[np.random.randint(0,1000)]\n",
    "            z_source1 = z_lens + z1_max # 1.2\n",
    "            z_source2 = random.uniform(z_source1 + 0.1, 2.) # 0.35\n",
    "            if(z_lens < 0.15): continue\n",
    "            if(z1_max < 0.2 or z_source1 > 2.): continue\n",
    "            if(double and z_source2 > 2.): continue\n",
    "            \n",
    "            redshifts = {'lens': z_lens, 'source1': z_source1, 'source2': z_source2}\n",
    "            angle, ratio = param.ellipticity2phi_q(row['SOF_BDF_G_1'], row['SOF_BDF_G_2'])\n",
    "            angle += 0.698132*random.uniform(-1, 1) #noise between -40 and 40 degrees\n",
    "            ratio = random.uniform(0.001, 1) #distribution for the axis ratio\n",
    "            e1, e2 = param.phi_q2_ellipticity(angle, ratio)\n",
    "            lens = {'sigma': random.uniform(300, 570), 'e1': e1, 'e2': e2} #single: 300-650\n",
    "            \n",
    "            status = simulation(model, coadd_id, redshifts, lens_image, lens, cuts, double, row)\n",
    "            \n",
    "            if(status[0] == 'ok'):\n",
    "                images, parameters = status[1], status[2]\n",
    "                sim_images = np.append(sim_images, [images[0]], axis = 0)\n",
    "                source_images = np.append(source_images, [images[1]], axis = 0)\n",
    "                lens_images = np.append(lens_images, [images[2]], axis = 0)\n",
    "                data_sim = data_sim.append(parameters, ignore_index=True)\n",
    "                num_sim += 1\n",
    "                pbar.update(1)\n",
    "                \n",
    "    sim_images = np.delete(sim_images, 0, axis = 0)\n",
    "    source_images = np.delete(source_images, 0, axis = 0)\n",
    "    lens_images = np.delete(lens_images, 0, axis = 0)\n",
    "    \n",
    "    images = [sim_images, source_images, lens_images]\n",
    "    return(images, data_sim)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_everything(seed, num_sim, double, name_file):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    hdu_list = fits.open(lenses_path)\n",
    "    lenses = hdu_list[1].data \n",
    "    complete_data = hdu_list[2].data[:]\n",
    "    complete_data = Table(complete_data)\n",
    "    complete_data = complete_data.to_pandas()\n",
    "    complete_data = complete_data.rename({'ZSPEC': 'Z_LENS'}, axis=1)\n",
    "    print(len(complete_data))\n",
    "    hdu_list.close()\n",
    "\n",
    "    images, data_sim = simulations_from_data(lenses, complete_data, num = num_sim, double=double)\n",
    "    write_fit_file(name_file, images, data_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ini_path = '/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/'\n",
    "path_dist = Ini_path + 'Data/source_distributions.csv'\n",
    "lenses_path = Ini_path + 'Data/Sim_complete/new_all_redmagic/' + 'all_redmagic_final.fits'\n",
    "file_path = ''\n",
    "\n",
    "if(cluster):\n",
    "    path_dist = 'source_distributions.csv'\n",
    "    lenses_path = 'all_redmagic_final.fits' #'lenses_cutouts.fits'\n",
    "    file_path = ''\n",
    "\n",
    "data_dist = distribution_data(path_dist)\n",
    "data_dist = data_dist[data_dist['MAG_PSF_G'] - data_dist['MAG_PSF_R'] > -2.2]\n",
    "data_dist = data_dist[data_dist['MAG_PSF_R'] - data_dist['MAG_PSF_I'] > -2.2]\n",
    "\n",
    "MMAX = 24.7\n",
    "MMIN = 19\n",
    "mmin, mmax, E_min, E_max, iso_min, iso_max, magni_min, magni_max = 19.2, 22.6, 0.2, 6.6, 0.4, 1000, 3.6, 1000\n",
    "theta_E_r_f_min, theta_E_r_f_max, min_image, max_image = 0.25, 1000., 1.3, 5.8\n",
    "min_col = 0.3\n",
    "cuts = {'E_max': E_max, 'E_min': E_min, 'mmax': mmax, 'mmin': mmin, 'iso_min': iso_min, 'iso_max': iso_max,\n",
    "        'magni_min': magni_min, 'magni_max': magni_max, 'theta_E_r_f_min': theta_E_r_f_min, \n",
    "        'theta_E_r_f_max': theta_E_r_f_max, 'min_image': min_image, 'max_image': max_image, 'min_col': 0.3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3972b8e0d74865ba200f803008bf91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pd.set_option('display.max_columns', None)\n",
    "seed, num_sim, double, filename = 65, 4000, False, 'simulation_file' # 4 2 False other\n",
    "if(cluster):\n",
    "    seed, num_sim, double, filename = sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4] \n",
    "    double = bool(strtobool(double))\n",
    "run_everything(int(seed), int(num_sim), double, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! convert -delay 50 -loop 0 *.png Only_sources_data.gif\n",
    "#! rm *.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
